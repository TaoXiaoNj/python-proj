from operator import itemgetter

from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI
from ai.ch11.hello_vector_store import get_vector_store

## è¿™å°±æ˜¯ RAG é‡Œé¢çš„ "R".
## Retriever çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯æ ¹æ®æ–‡æœ¬æŸ¥è¯¢å‡ºå¯¹åº”çš„ Document
## Retriever æ˜¯ä¸€ä¸ªæ¥å£ï¼Œé™¤äº†å‘é‡æ•°æ®åº“ï¼Œè¿˜å¯ä»¥æ”¯æŒå…¶ä»–çš„å®ç°ï¼Œ
## ä¾‹å¦‚ WikipediaRetriever
retriever: VectorStoreRetriever = get_vector_store().as_retriever(search_type='similarity')


session_history_store = {}

def get_session_history(session_id: str):
    if session_id not in session_history_store:
        session_history_store[session_id] = InMemoryChatMessageHistory()
    return session_history_store[session_id]


chat_model = ChatOpenAI()

## è¿™ä¸ªæç¤ºè¯æ¨¡æ¿ï¼ŒåŒ…å«äº†ï¼š
##   - ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰ï¼Œä¹Ÿå°±æ˜¯æ ¹æ®é—®é¢˜ä»å‘é‡æ•°æ®åº“æ£€ç´¢å‡ºæ¥çš„å†…å®¹
##   - èŠå¤©å†å²
##   - ç”¨æˆ·é—®é¢˜
prompt = ChatPromptTemplate.from_messages([
    (
        'system',
        """ä½ æ˜¯ä¸€ä¸ªé—®é¢˜å›ç­”åŠ©æ‰‹ã€‚ä½ å¯ä»¥å‚è€ƒä¸‹é¢æä¾›çš„ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“æˆ–è€…ä¸ç¡®å®šï¼Œå°±å›ç­”ã€ä¿ºä¸çŸ¥é“ã€‘ã€‚å›ç­”æ—¶å°½å¯èƒ½ç®€æ´ã€‚
        contextï¼š{context}"""
    ),
    MessagesPlaceholder(variable_name='history'),
    (
        'human', '{question}'
    )
])


## retriever æ£€ç´¢çš„ç»“æœæ˜¯ä¸€ä¸ªæ–‡æ¡£åˆ—è¡¨ï¼Œæˆ‘ä»¬å¿…é¡»æŠŠå®ƒä»¬è½¬åŒ–æˆæ–‡æœ¬åï¼Œ
## æ‰èƒ½ä¼ ç»™å¤§æ¨¡å‹
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

context = itemgetter('question') | retriever | format_docs
first_step = RunnablePassthrough.assign(context=context)
chain = first_step | prompt | chat_model

config = {'configurable': {'session_id': 'TaoXiao'}}

with_rag_and_history = RunnableWithMessageHistory(
    chain,
    get_session_history=get_session_history,
    input_messages_key='question',
    history_messages_key='history'
)

if __name__ == '__main__':
    while True:
        user_input = input('ä½ > ')
        if user_input.lower() == 'exit':
            print('å†è§ ğŸ‘‹')
            break

        stream = with_rag_and_history.stream(
            {'question': user_input},
            config=config
        )

        for chunk in stream:
            print(chunk.content, end='', flush=True)

        print()